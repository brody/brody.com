---
title: "How AI Agents Misbehave When Faced With Real-World Pressures"
author: "[[Matthew Hutson]]"
pubDate: 2025-11-27T15:13:31+11:00
tags:
  - "clippings"
published: 2025-11-26
sourceTitle: "How AI Agents Misbehave When Faced With Real-World Pressures"
source: "https://spectrum.ieee.org/ai-agents-safety"
imageUrl: "https://spectrum.ieee.org/media-library/image.jpg?id=62224940&width=1200&height=600&coordinates=0%2C779%2C0%2C21"
description: "PropensityBench reveals AI agents' risky behavior under pressure, highlighting the need for improved alignment to ensure AI safety."
faviconUrl: "https://assets.rebelmouse.io/eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpbWFnZSI6Imh0dHBzOi8vYXNzZXRzLnJibC5tcy8yNjU5NjY0OS9vcmlnaW4ucG5nIiwiZXhwaXJlc19hdCI6MTc4NTc0NjUwNn0.pFbPADvK9fyfasig9FMci3xf6UeB_WJaER5Yea_eRpI/img.png?width=48&height=48"
---
Several AI agents were tested to see if they would break assigned rules when faced with deadlines and other kinds of pressure. 

Google Gemini 2.5 was the worst offender, breaking rules 79% of the time under pressure. Even under zero pressure, the AI agents still broke assigned rules 19% of the time.